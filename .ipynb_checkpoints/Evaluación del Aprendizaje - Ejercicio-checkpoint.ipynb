{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio en clase: Evaluación del aprendizaje\n",
    "\n",
    "Este ejercicio tiene como objetivos:\n",
    "\n",
    "* Experimentar con herramientas para la evaluación del rendimiento de modelos de aprendizaje supervisado.\n",
    "* Explorar medidas de evaluación tales como exactitud, matriz de confusión, precisión y exhaustividad.\n",
    "* Graficar e interpretar curvas ROC y curvas de precisión-exhaustividad.\n",
    "\n",
    "Como conjunto de datos vamos a utilizar un subconjunto del [Mushroom Data Set](https://archive.ics.uci.edu/ml/datasets/Mushroom) del UCI Machine Learning Repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento y selección de características\n",
    "\n",
    "### Cargar el conjunto de datos\n",
    "\n",
    "Estos datos contienen la descripción de muestras hipotéticas de 23 especies de setas con aletas de las familias Agaricus y Lepiota. Cada especie es clasificada como venenosa *(poisonous)* o comestible *(edible)*. [Descripción completa del DataSet](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "datos = pd.read_csv('mushrooms.csv')\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separemos la clase de las demás características. Tomaremos la clase **comestible** (e) como positiva (+1) y *venenosa* (p) como negativa (-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * (datos['class'] == 'e') - 1   # +1 si (datos['class'] == 'e') == True == 1; -1 si (datos['class'] == 'e') == False == 0\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Este conjunto de datos es perfectamente separable, por lo que es posible hacer predicciones con un 100% de exactitud. Para aprovechar mejor el ejercicio, vamos a usar solamente 4 de las 23 caracterìsticas:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datos[['cap-shape','bruises','gill-color','stalk-root']]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de datos categóricos\n",
    "\n",
    "Antes de continuar necesitamos convertir los datos categóricos en datos numéricos. Dado que los valores de las columnas no son ordinales, preferimos usar indicadores binarios *(one-hot encoding)* para cada valor de las variables independientes. Pandas tiene una función muy práctica para ello, llamada [`get_dummies`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de un clasificador de regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "modelo = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo\n",
    "\n",
    "### Exactitud\n",
    "\n",
    "En nuestros anteriores ejercicios hemos venido calculando la exactitud *(accuracy)* del modelo, definida como:\n",
    "\n",
    "$$\n",
    "\\mbox{exactitud} = \\frac{\\mbox{# predicciones correctas}}{\\mbox{# total de muestras}} \n",
    "$$\n",
    "\n",
    "A continuación calcularemos la exactitud del modelo en el **conjunto de prueba** y veremos también el modo de obtener este valor directamente con `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "predicciones_test = modelo.predict(X_test)\n",
    "num_predicciones_correctas = (y_test == predicciones_test).sum()\n",
    "num_total_de_muestras = len(y_test)\n",
    "exactitud = num_predicciones_correctas / num_total_de_muestras\n",
    "\n",
    "print ( 'Predicciones correctas : ', num_predicciones_correctas )\n",
    "print ( 'Número de muestras     : ', num_total_de_muestras )\n",
    "print ( 'Exactitud (manual)     : ', exactitud )\n",
    "\n",
    "# Usando scikit-learn\n",
    "print ( 'Exactitud (score)      : ', modelo.score(X_test, y_test) )\n",
    "print ( 'Exactitud (metrics)    : ', metrics.accuracy_score(y_test, predicciones_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión\n",
    "\n",
    "La matriz de confusión es un sumario del rendimiento de un clasificador.\n",
    "\n",
    "<img src=\"http://www.nature.com/nmeth/journal/v13/n8/images/nmeth.3945-F1.jpg\" style=\"width: 500px;\"/>\n",
    "\n",
    "Para obtener sus valores usamos el método [`metrics.confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusion = metrics.confusion_matrix(y_test, predicciones_test)\n",
    "\n",
    "# Mapeo según http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "TN = matriz_confusion[0,0]\n",
    "FN = matriz_confusion[1,0]\n",
    "FP = matriz_confusion[0,1]\n",
    "TP = matriz_confusion[1,1]\n",
    "\n",
    "print ('              +-----------------+')\n",
    "print ('              |   Predicción    |')\n",
    "print ('              +-----------------+')\n",
    "print ('              |    +   |    -   |')\n",
    "print ('+-------+-----+--------+--------+')\n",
    "print ('| Valor |  +  |   %d |   %d   |'   % (TP, FN) )\n",
    "print ('| real  +-----+--------+--------+')\n",
    "print ('|       |  -  |   %d  |   %d  |'    % (FP, TN) )\n",
    "print ('+-------+-----+--------+--------+')\n",
    "print ()\n",
    "print ( 'Exactitud    : ', (TP+TN)/(TP+FN+FP+TN) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 1:** ¿Cuántas de las setas venenosas del conjunto de prueba fueron clasificadas como comestibles por el modelo?\n",
    "\n",
    "**Pregunta 2:** ¿Qué nombre recibe el valor indicado en la pregunta 1?\n",
    "\n",
    "**Pregunta 3:** ¿Qué proporción de las setas venenosas fueron clasificadas correctamente?\n",
    "\n",
    "**Pregunta 4:** ¿Qué nombre recibe el valor indicado en la pregunta 3?\n",
    "\n",
    "**Pregunta 5:** ¿Qué proporción de las setas comestibles fueron clasificadas correctamente?\n",
    "\n",
    "**Pregunta 6:** ¿Qué nombre recibe el valor indicado en la pregunta 5?\n",
    "\n",
    "**Pregunta 7:** ¿Qué proporción de las setas clasificadas como comestibles son realmente comestibles?\n",
    "\n",
    "**Pregunta 8:** ¿Qué nombre recibe el valor indicado en la pregunta 7?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( 'Pregunta 1    : ', ... ) ## COMPLETAR...\n",
    "print ( 'Pregunta 3    : ', ... ) ## COMPLETAR...\n",
    "print ( 'Pregunta 5    : ', ... ) ## COMPLETAR...\n",
    "print ( 'Pregunta 7    : ', ... ) ## COMPLETAR..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando el costo de los errores\n",
    "\n",
    "Ponte en el caso de un conjunto de exploradores que dependen del modelo que hemos entrenado para alimentarse de setas. Que se clasifique como venenosa una seta comestible es claramente menos perjudicial que clasificar como comestible una seta venenosa. En otras palabras, **en nuestro caso los falsos negativos cuestan menos que los falsos positivos**.\n",
    "\n",
    "Supongamos que podemos cuantificar este costo:\n",
    "1. S/ 1.00 por cada falso negativo\n",
    "2. S/ 1,000.00 por cada falso positivo\n",
    "3. Las clasificaciones correctas no representan costo alguno\n",
    "\n",
    "**Pregunta 9:** Bajo el supuesto indicado, ¿cuál sería el costo total asociado al rendimiento del modelo de regresión logística en el **conjunto de pruebas**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( 'Costo total del modelo en el conjunto de pruebas : S/', ... )  ## COMPLETAR..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva ROC\n",
    "\n",
    "Recordemos que el modelo de regresión logística es optimizado para predecir la probabilidad de que un ejemplo sea positivo, prediciendo $+1$ cuando esta probabilidad es mayor que el **umbral** de $0.5$. Podemos verificarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidades_test = modelo.predict_proba(X_test)\n",
    "print ('Probabilidad de la clase negativa y de la clase positiva :')\n",
    "print (probabilidades_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos +1 siempre que la probabilidad de la clase positiva sea mayor a 0.5\n",
    "predicciones_test = np.where(probabilidades_test[:,1] > 0.5, +1, -1) \n",
    "print ( 'Exactitud : ', metrics.accuracy_score(y_test, predicciones_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si variamos el valor del umbral, podemos controlar el **nivel de confianza** que le exigimos al modelo para sus predicciones. Dependiendo del valor elegido para el umbral, el número de verdaderos positivos y de falsos positivos variarán de manera complementaria con relación al número total de positivos. Esto es lo que se grafica en una curva ROC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, umbrales = metrics.roc_curve(y_test, probabilidades_test[:,1])\n",
    "auc_roc = metrics.roc_auc_score(y_test, probabilidades_test[:,1])\n",
    "\n",
    "plt.rcParams.update({'font.size': 9})\n",
    "plt.plot(fpr, tpr, label= (\"Curva ROC\") )\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (exhaustividad)\")\n",
    "plt.title((\"Curva ROC (AUC = %.4f)\" % auc_roc))\n",
    "# ubicamos el punto más cercano a 0.5\n",
    "umbral_05 = np.argmin(np.abs(umbrales - 0.5))\n",
    "plt.plot(fpr[umbral_05], tpr[umbral_05], 'o', markersize=10,\n",
    "         label=\"Umbral 0.5\", fillstyle=\"none\", c='r', mew=2)\n",
    "plt.legend(loc='best', numpoints = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 10:** Según la curva ROC del modelo, ¿cuál de las siguientes dos medidas es mayor en el punto de operación correspondiente al umbral de probabilidad $0.5$: exhaustividad o tasa de falsos positivos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisión y exhaustividad\n",
    "\n",
    "En casos como este, no nos importa tanto el número total de errores sino más bien disminuir el número de falsos positivos, lo cual implica aumentar la **precisión**:\n",
    "\n",
    "$$\n",
    "\\mbox{precisión} = \\frac{\\text{# ejemplos positivos clasificados como positivos}}{\\text{# ejemplos clasificados como positivos}} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "Obtengamos la precisión de nuestro modelo en el conjunto de pruebas (umbral por defecto $0.5$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( 'Precisión           : ', TP/(TP+FP) ) \n",
    "\n",
    "# Usando scikit-learn\n",
    "print ( 'Precisión (metrics) : ', metrics.precision_score(y_test, predicciones_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La exhaustividad *(recall)* es una medida complementaria a la precisión:\n",
    "    \n",
    "$$\n",
    "\\mbox{exhaustividad} = \\frac{\\text{# ejemplos positivos clasificados como positivos}}{\\text{# ejemplos positivos}} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Obtengamos la exhastividad de nuestro modelo en el conjunto de pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( 'Exhaustividad           : ', TP/(TP+FN) ) \n",
    "\n",
    "# Usando scikit-learn\n",
    "print ( 'Exhaustividad (metrics) : ', metrics.recall_score(y_test, predicciones_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 11:** ¿Cuál será la exhaustividad de un modelo que prediga siempre $+1$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para mejorar la precisión, podemos intentar exigir un mayor nivel de confianza en las predicciones. Veamos lo que ocurre si establecemos un umbral alto de $0.92$ y uno muy alto de $0.95$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ( 'Umbral 0.5' )\n",
    "print ( '----------' )\n",
    "print ( 'Número de predicciones positivas : ', (predicciones_test == 1).sum() )\n",
    "print ( 'Exactitud     : ', metrics.accuracy_score(y_test, predicciones_test) )\n",
    "print ( 'Precisión     : ', metrics.precision_score(y_test, predicciones_test) )\n",
    "print ( 'Exhaustividad : ', metrics.recall_score(y_test, predicciones_test) )\n",
    "\n",
    "print ()\n",
    "\n",
    "predicciones_test_umbral_alto = np.where(probabilidades_test[:,1] > 0.92, +1, -1) \n",
    "print ( 'Umbral 0.92' )\n",
    "print ( '-----------' )\n",
    "print ( 'Número de predicciones positivas : ', (predicciones_test_umbral_alto == 1).sum() )\n",
    "print ( 'Exactitud     : ', metrics.accuracy_score(y_test, predicciones_test_umbral_alto) )\n",
    "print ( 'Precisión     : ', metrics.precision_score(y_test, predicciones_test_umbral_alto) )\n",
    "print ( 'Exhaustividad : ', metrics.recall_score(y_test, predicciones_test_umbral_alto) )\n",
    "print ()\n",
    "\n",
    "predicciones_test_umbral_muy_alto = np.where(probabilidades_test[:,1] > 0.95, +1, -1) \n",
    "print ( 'Umbral 0.95' )\n",
    "print ( '-----------' )\n",
    "print ( 'Número de predicciones positivas : ', (predicciones_test_umbral_muy_alto == 1).sum() )\n",
    "print ( 'Exactitud     : ', metrics.accuracy_score(y_test, predicciones_test_umbral_muy_alto) )\n",
    "print ( 'Precisión     : ', metrics.precision_score(y_test, predicciones_test_umbral_muy_alto) )\n",
    "print ( 'Exhaustividad : ', metrics.recall_score(y_test, predicciones_test_umbral_muy_alto) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 12:** ¿En el umbral $0.95$ se tiene una mayor precisión que en $0.5$?\n",
    "\n",
    "**Pregunta 13:** ¿Aumentar el umbral garantiza un aumento de la precisión?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curva de precisión-exhaustividad\n",
    "\n",
    "Examina la curva de precisión-exhaustividad, en la que marcaremos los tres umbrales anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, exhaustividad, umbrales = metrics.precision_recall_curve(y_test, probabilidades_test[:,1])\n",
    "precision_media = metrics.average_precision_score(y_test, probabilidades_test[:,1])\n",
    "\n",
    "plt.plot(precision, exhaustividad, label= (\"Curva de Precisión-Exhaustividad\"), c='m' )\n",
    "plt.xlabel(\"Precisión\")\n",
    "plt.ylabel(\"Exhaustividad\")\n",
    "plt.title((\"Curva de Precisión-Exhaustividad (Precisión media = %.4f)\" % precision_media))\n",
    "\n",
    "umbral_05 = np.argmin(np.abs(umbrales - 0.5))\n",
    "plt.plot(precision[umbral_05], exhaustividad[umbral_05], 'o', markersize=10,\n",
    "         label=\"Umbral 0.5\", fillstyle=\"none\", c='r', mew=2)\n",
    "\n",
    "umbral_092 = np.argmin(np.abs(umbrales - 0.92))\n",
    "plt.plot(precision[umbral_092], exhaustividad[umbral_092], 'o', markersize=10,\n",
    "         label=\"Umbral 0.92\", fillstyle=\"none\", c='g', mew=2)\n",
    "\n",
    "umbral_095 = np.argmin(np.abs(umbrales - 0.95))\n",
    "plt.plot(precision[umbral_095], exhaustividad[umbral_095], 'o', markersize=10,\n",
    "         label=\"Umbral 0.95\", fillstyle=\"none\", c='b', mew=2)\n",
    "\n",
    "plt.gca().set_xlim([0,1])\n",
    "plt.gca().set_ylim([0,1])\n",
    "plt.legend(loc='best', numpoints = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escogiendo un punto de operación\n",
    "\n",
    "Supongamos que queremos buscar como punto de operación el umbral que resulte en la mayor exhaustividad con una precisión igual o mayor a 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbrales_precision_exhaustividad = pd.DataFrame({ \n",
    "        'Exhaustividad' : exhaustividad,\n",
    "        'Precisión' : precision,\n",
    "        'Umbrales' : np.append(umbrales, 1) # El último umbral es siempre 1\n",
    "    })\n",
    "\n",
    "umbrales_precision_exhaustividad[umbrales_precision_exhaustividad['Precisión'] >= .95].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta 14:** ¿Si queremos alcanzar una precisión de 95%, qué nivel mínimo de confianza debemos exigir a la probabilidad producida por el modelo?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
